{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-05-08T10:11:00.105127Z","iopub.status.busy":"2024-05-08T10:11:00.104819Z","iopub.status.idle":"2024-05-08T10:11:41.889727Z","shell.execute_reply":"2024-05-08T10:11:41.888856Z","shell.execute_reply.started":"2024-05-08T10:11:00.105100Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import seaborn as sns\n","import plotly.graph_objects as go\n","import itertools\n","import re\n","\n","from sklearn.model_selection import train_test_split\n","from pprint import pprint\n","from collections import Counter\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.preprocessing import LabelBinarizer\n","from sklearn.metrics import ConfusionMatrixDisplay\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.regularizers import l1, l2\n","from sklearn.metrics import confusion_matrix, classification_report\n","from nltk.stem.snowball import SnowballStemmer\n","from nltk.stem.wordnet import WordNetLemmatizer"]},{"cell_type":"markdown","metadata":{},"source":["# Load data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T10:11:41.891733Z","iopub.status.busy":"2024-05-08T10:11:41.891213Z","iopub.status.idle":"2024-05-08T10:11:42.194230Z","shell.execute_reply":"2024-05-08T10:11:42.193312Z","shell.execute_reply.started":"2024-05-08T10:11:41.891708Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Review</th>\n","      <th>Rating</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>nice hotel expensive parking got good deal sta...</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ok nothing special charge diamond member hilto...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>nice rooms not 4* experience hotel monaco seat...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>unique, great stay, wonderful time hotel monac...</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>great stay great stay, went seahawk game aweso...</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                              Review  Rating\n","0  nice hotel expensive parking got good deal sta...       4\n","1  ok nothing special charge diamond member hilto...       2\n","2  nice rooms not 4* experience hotel monaco seat...       3\n","3  unique, great stay, wonderful time hotel monac...       5\n","4  great stay great stay, went seahawk game aweso...       5"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv(\"/kaggle/input/trip-advisor-hotel-reviews/tripadvisor_hotel_reviews.csv\")\n","df.head()"]},{"cell_type":"markdown","metadata":{},"source":["The reviews appear to be somewhat preprocessed:\n","* There are no capital letters or full stops, but there is other punctuation like commas and apostrophes.\n","* Sentences don't flow very well, presumably because stop words like \"I\", \"the\" and \"a\" have been removed.\n","* Words have clearly been tokenized, because \"n't\" appears in isolation a lot.\n","* There are many plurals, suggesting that words were not converted to singular.\n","* Some words weren't tokenized correctly due to missing spaces, for example \"shower.before\".\n","* There are some misspellings, for example \"ass told\" instead of \"as told\".\n","* The reviews seem to all end with commas, suggesting that full stops have been converted to commas.\n","\n","It seems we can leverage this preprocessing and just tokenize by splitting on spaces.\n","\n","The ratings appear to be integers between 1 and 5."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-22T14:14:59.148161Z","iopub.status.busy":"2023-10-22T14:14:59.147807Z","iopub.status.idle":"2023-10-22T14:14:59.177469Z","shell.execute_reply":"2023-10-22T14:14:59.176587Z","shell.execute_reply.started":"2023-10-22T14:14:59.148133Z"},"trusted":true},"outputs":[],"source":["df.info()"]},{"cell_type":"markdown","metadata":{},"source":["There are 20491 data points. There are no null reviews or ratings. All ratings are integers."]},{"cell_type":"markdown","metadata":{},"source":["# Exploratory data analysis"]},{"cell_type":"markdown","metadata":{},"source":["## Are all the ratings between 1 and 5? What's the distribution of ratings?"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-22T14:14:59.180611Z","iopub.status.busy":"2023-10-22T14:14:59.180012Z","iopub.status.idle":"2023-10-22T14:14:59.187191Z","shell.execute_reply":"2023-10-22T14:14:59.186307Z","shell.execute_reply.started":"2023-10-22T14:14:59.180585Z"},"trusted":true},"outputs":[],"source":["df[\"Rating\"].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-22T14:14:59.188805Z","iopub.status.busy":"2023-10-22T14:14:59.188467Z","iopub.status.idle":"2023-10-22T14:14:59.68337Z","shell.execute_reply":"2023-10-22T14:14:59.682535Z","shell.execute_reply.started":"2023-10-22T14:14:59.18877Z"},"trusted":true},"outputs":[],"source":["sns.countplot(data=df, x=\"Rating\", palette=\"viridis\").set_title(\"Distribution of ratings\")"]},{"cell_type":"markdown","metadata":{},"source":["The ratings are all integers between 1 and 5.\n","\n","The ratings are unevenly distributed, with more positive reviews being more common."]},{"cell_type":"markdown","metadata":{},"source":["## What's the longest length of a review?"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-22T14:14:59.684717Z","iopub.status.busy":"2023-10-22T14:14:59.68439Z","iopub.status.idle":"2023-10-22T14:14:59.708195Z","shell.execute_reply":"2023-10-22T14:14:59.707175Z","shell.execute_reply.started":"2023-10-22T14:14:59.684682Z"},"trusted":true},"outputs":[],"source":["df[\"Length\"] = df[\"Review\"].apply(len)\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-22T14:14:59.709648Z","iopub.status.busy":"2023-10-22T14:14:59.709369Z","iopub.status.idle":"2023-10-22T14:15:00.58061Z","shell.execute_reply":"2023-10-22T14:15:00.57964Z","shell.execute_reply.started":"2023-10-22T14:14:59.709624Z"},"trusted":true},"outputs":[],"source":["sns.displot(data=df, x=\"Length\", hue=\"Rating\", palette=\"viridis\", kind=\"kde\", fill=True, aspect=4)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-22T14:15:00.5823Z","iopub.status.busy":"2023-10-22T14:15:00.581973Z","iopub.status.idle":"2023-10-22T14:15:00.595496Z","shell.execute_reply":"2023-10-22T14:15:00.594565Z","shell.execute_reply.started":"2023-10-22T14:15:00.582251Z"},"trusted":true},"outputs":[],"source":["df[\"Length\"].describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-22T14:15:00.597334Z","iopub.status.busy":"2023-10-22T14:15:00.596865Z","iopub.status.idle":"2023-10-22T14:15:00.605615Z","shell.execute_reply":"2023-10-22T14:15:00.604594Z","shell.execute_reply.started":"2023-10-22T14:15:00.597298Z"},"trusted":true},"outputs":[],"source":["df[\"Length\"].mode()"]},{"cell_type":"markdown","metadata":{},"source":["Now let's look at the length in terms of words."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-22T14:15:00.610313Z","iopub.status.busy":"2023-10-22T14:15:00.609991Z","iopub.status.idle":"2023-10-22T14:15:00.948563Z","shell.execute_reply":"2023-10-22T14:15:00.947559Z","shell.execute_reply.started":"2023-10-22T14:15:00.610277Z"},"trusted":true},"outputs":[],"source":["df[\"Length in words\"] = df[\"Review\"].str.split().apply(len)\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-22T14:15:00.949926Z","iopub.status.busy":"2023-10-22T14:15:00.949657Z","iopub.status.idle":"2023-10-22T14:15:01.649778Z","shell.execute_reply":"2023-10-22T14:15:01.648823Z","shell.execute_reply.started":"2023-10-22T14:15:00.949902Z"},"trusted":true},"outputs":[],"source":["sns.displot(data=df, x=\"Length in words\", hue=\"Rating\", palette=\"viridis\", kind=\"kde\", fill=True, aspect=4)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-22T14:15:01.651297Z","iopub.status.busy":"2023-10-22T14:15:01.650963Z","iopub.status.idle":"2023-10-22T14:15:01.662493Z","shell.execute_reply":"2023-10-22T14:15:01.661571Z","shell.execute_reply.started":"2023-10-22T14:15:01.651246Z"},"trusted":true},"outputs":[],"source":["df[\"Length in words\"].describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-22T14:15:01.664046Z","iopub.status.busy":"2023-10-22T14:15:01.663711Z","iopub.status.idle":"2023-10-22T14:15:01.672017Z","shell.execute_reply":"2023-10-22T14:15:01.671149Z","shell.execute_reply.started":"2023-10-22T14:15:01.664019Z"},"trusted":true},"outputs":[],"source":["df[\"Length in words\"].mode()"]},{"cell_type":"markdown","metadata":{},"source":["The reviews range from 44 to 13501 characters, with a median of 537. The most common lengths are 403 and 444.\n","\n","In terms of words, the reviews range from length 7 to 1931, with a median of 77. The most common length is 48."]},{"cell_type":"markdown","metadata":{},"source":["## Are there any odd characters?"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-22T14:15:01.673591Z","iopub.status.busy":"2023-10-22T14:15:01.673227Z","iopub.status.idle":"2023-10-22T14:15:01.911042Z","shell.execute_reply":"2023-10-22T14:15:01.910068Z","shell.execute_reply.started":"2023-10-22T14:15:01.673557Z"},"trusted":true},"outputs":[],"source":["chars = set()\n","\n","for item in df[\"Review\"]:\n","    chars = chars.union(item)\n","    \n","chars = sorted(chars)\n","\n","print(chars)"]},{"cell_type":"markdown","metadata":{},"source":["Indeed, there are some odd characters. We should probably do something about them."]},{"cell_type":"markdown","metadata":{},"source":["## Are all the reviews in English?\n","\n","From the list of characters, we see that a lot of non-English characters appear. Let's find some reviews containing these characters."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-22T14:15:01.91231Z","iopub.status.busy":"2023-10-22T14:15:01.912033Z","iopub.status.idle":"2023-10-22T14:15:01.958047Z","shell.execute_reply":"2023-10-22T14:15:01.957158Z","shell.execute_reply.started":"2023-10-22T14:15:01.912286Z"},"trusted":true},"outputs":[],"source":["def find_review_by_character(c):\n","    for review in df[\"Review\"]:\n","        if c in review and len(review) < 1000:\n","            return review\n","\n","# Print a review for each non-English character\n","for c in ['À', 'Â', 'Ä', 'Ç', 'È', 'Ù', 'Û', 'Ü', 'à', 'â', 'ã', 'ä', 'å', 'æ', 'ç', 'è', 'é', 'ê', 'ë', 'î', 'ö']:\n","    pprint(find_review_by_character(c))\n","    print()"]},{"cell_type":"markdown","metadata":{},"source":["The reviews above are all English, and the non-English characters look like artifacts from some kind of data processing or encoding error."]},{"cell_type":"markdown","metadata":{},"source":["## What are the most common words?"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-22T14:15:01.959335Z","iopub.status.busy":"2023-10-22T14:15:01.959046Z","iopub.status.idle":"2023-10-22T14:15:24.319038Z","shell.execute_reply":"2023-10-22T14:15:24.318018Z","shell.execute_reply.started":"2023-10-22T14:15:01.959311Z"},"trusted":true},"outputs":[],"source":["plt.figure(figsize=(20,20))\n","wc = WordCloud(max_words=1000, min_font_size=10, height=800, width=1600,\n","               background_color=\"white\", colormap=\"viridis\").generate(\" \".join(df[\"Review\"]))\n","\n","plt.imshow(wc)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-22T14:15:24.320563Z","iopub.status.busy":"2023-10-22T14:15:24.320251Z","iopub.status.idle":"2023-10-22T14:15:25.339441Z","shell.execute_reply":"2023-10-22T14:15:25.338344Z","shell.execute_reply.started":"2023-10-22T14:15:24.320539Z"},"trusted":true},"outputs":[],"source":["texts = df[\"Review\"]\n","new = texts.str.split()\n","new = new.values.tolist()\n","corpus = [word for i in new for word in i]\n","counter = Counter(corpus)\n","most = counter.most_common()\n","x, y = [], []\n","for word, count in most[:30]:\n","    x.append(word)\n","    y.append(count)\n","\n","fig = go.Figure(go.Bar(\n","            x=y,\n","            y=x,\n","            orientation='h',  marker=dict(\n","        color='rgba(50, 171, 96, 0.6)',\n","        line=dict(\n","            color='rgba(50, 171, 96, 1.0)',\n","            width=1),\n","    ),\n","    name='Most common Word',))\n","\n","fig.update_layout( title={\n","        'text': \"Most Common Words\",\n","        'y':0.9,\n","        'x':0.5,\n","        'xanchor': 'center',\n","        'yanchor': 'top'}, font=dict(\n","        family=\"Courier New, monospace\",\n","        size=18,\n","        color=\"RebeccaPurple\"\n","    ))\n","\n","fig.show()"]},{"cell_type":"markdown","metadata":{},"source":["## What are some common n-grams?"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-22T14:15:25.341237Z","iopub.status.busy":"2023-10-22T14:15:25.340702Z","iopub.status.idle":"2023-10-22T14:15:25.34767Z","shell.execute_reply":"2023-10-22T14:15:25.346808Z","shell.execute_reply.started":"2023-10-22T14:15:25.341209Z"},"trusted":true},"outputs":[],"source":["def _get_top_ngram(corpus, n=None):\n","    #getting top ngrams\n","    vec = CountVectorizer(ngram_range=(n, n),\n","                          max_df=0.9,\n","                          ).fit(corpus)\n","    bag_of_words = vec.transform(corpus)\n","    sum_words = bag_of_words.sum(axis=0)\n","    words_freq = [(word, sum_words[0, idx])\n","                  for word, idx in vec.vocabulary_.items()]\n","    words_freq = sorted(words_freq, key=lambda x: x[1], reverse=True)\n","    return words_freq[:15]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-22T14:15:25.34938Z","iopub.status.busy":"2023-10-22T14:15:25.349021Z","iopub.status.idle":"2023-10-22T14:15:44.629886Z","shell.execute_reply":"2023-10-22T14:15:44.628957Z","shell.execute_reply.started":"2023-10-22T14:15:25.349348Z"},"trusted":true},"outputs":[],"source":["# Show most common 3-grams\n","\n","fig = make_subplots(rows=1, cols=1)\n","\n","texts = df[\"Review\"]\n","\n","new = texts.str.split()\n","new = new.values.tolist()\n","corpus = [word for i in new for word in i]\n","\n","top_n_bigrams = _get_top_ngram(texts, 3)[:15]\n","x, y = map(list, zip(*top_n_bigrams))\n","\n","fig.add_trace(go.Bar(\n","            x=y,\n","            y=x,\n","            orientation='h', type=\"bar\",\n","    name=\"3-grams\", marker=dict(color=\"lightgreen\")), 1, 1),\n","\n","fig.update_layout(\n","    autosize=False,\n","    width=2000,\n","    height=600,title=dict(\n","        text='<b>Most Common trigrams</b>',\n","        x=0.5,\n","        y=0.95,\n","        font=dict(\n","        family=\"Courier New, monospace\",\n","        size=24,\n","        color=\"RebeccaPurple\"\n","        )\n","    ))\n","    \n","fig.show()"]},{"cell_type":"markdown","metadata":{},"source":["## How many distinct words are there?"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-22T14:15:44.631796Z","iopub.status.busy":"2023-10-22T14:15:44.631172Z","iopub.status.idle":"2023-10-22T14:15:45.136414Z","shell.execute_reply":"2023-10-22T14:15:45.135455Z","shell.execute_reply.started":"2023-10-22T14:15:44.631767Z"},"trusted":true},"outputs":[],"source":["reviews = df[\"Review\"]\n","reviews = reviews.str.split()\n","reviews = reviews.values.tolist()\n","words = set(word for review in reviews for word in review)\n","print(f\"There are {len(words)} distinct words.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-22T14:15:45.137889Z","iopub.status.busy":"2023-10-22T14:15:45.1376Z","iopub.status.idle":"2023-10-22T14:15:45.142817Z","shell.execute_reply":"2023-10-22T14:15:45.141943Z","shell.execute_reply.started":"2023-10-22T14:15:45.137864Z"},"trusted":true},"outputs":[],"source":["# Sanity check\n","print(\"Some example words:\", list(itertools.islice(words, 10)))"]},{"cell_type":"markdown","metadata":{},"source":["There are 102,008 different words, which is quite a lot!\n","\n","According to [a blog post on wordcounter.io](https://wordcounter.io/blog/how-many-words-are-in-the-english-language#:~:text=The%20Second%20Edition%20of%20the,Section%2C%20includes%20some%20470%2C000%20entries.), 3,000 commonly used words cover 95% of everyday writing. This means there must be a huge number of spurious words in this dataset. We should probably clean up this data."]},{"cell_type":"markdown","metadata":{},"source":["# Train model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-22T14:21:37.9099Z","iopub.status.busy":"2023-10-22T14:21:37.909421Z","iopub.status.idle":"2023-10-22T14:21:37.92924Z","shell.execute_reply":"2023-10-22T14:21:37.928377Z","shell.execute_reply.started":"2023-10-22T14:21:37.909866Z"},"trusted":true},"outputs":[],"source":["X_train, X_val, y_train, y_val = train_test_split(df[\"Review\"], df[\"Rating\"], test_size=0.2, random_state=RANDOM_SEED)\n","\n","# Sparse categorical crossentropy needs labels between 0 and N-1, so we need to subtract 1 from the ratings\n","y_train -= 1\n","y_val -= 1"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-22T14:25:11.221996Z","iopub.status.busy":"2023-10-22T14:25:11.221618Z","iopub.status.idle":"2023-10-22T14:25:41.917615Z","shell.execute_reply":"2023-10-22T14:25:41.916609Z","shell.execute_reply.started":"2023-10-22T14:25:11.221965Z"},"trusted":true},"outputs":[],"source":["tmp_train_ds = tf.data.Dataset.from_tensor_slices(X_train)\n","\n","tmp_vectorize = tf.keras.layers.TextVectorization()\n","\n","tmp_vectorize.adapt(tmp_train_ds)\n","\n","vocab_size = tmp_vectorize.vocabulary_size()\n","print(f\"Vocab size before preprocessing: {vocab_size}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-22T14:24:56.929165Z","iopub.status.busy":"2023-10-22T14:24:56.92877Z","iopub.status.idle":"2023-10-22T14:24:56.934742Z","shell.execute_reply":"2023-10-22T14:24:56.933821Z","shell.execute_reply.started":"2023-10-22T14:24:56.929134Z"},"trusted":true},"outputs":[],"source":["stemmer = SnowballStemmer(\"english\")\n","\n","def custom_preprocessing(text):\n","    # Stem words to reduce the number of distinct words - this should reduce overfitting\n","    text = \" \".join(stemmer.stem(word) for word in text.split())\n","    # Ensure the comma (sentence separator) gets its own token and is not stripped out\n","    text = re.sub(r', ', r' newsentence ', text)\n","    return text"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_train = X_train.apply(custom_preprocessing)\n","X_val = X_val.apply(custom_preprocessing)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-22T14:25:41.919437Z","iopub.status.busy":"2023-10-22T14:25:41.919119Z","iopub.status.idle":"2023-10-22T14:26:53.869613Z","shell.execute_reply":"2023-10-22T14:26:53.868489Z","shell.execute_reply.started":"2023-10-22T14:25:41.919411Z"},"trusted":true},"outputs":[],"source":["tmp_train_ds = tf.data.Dataset.from_tensor_slices(X_train)\n","\n","tmp_vectorize = tf.keras.layers.TextVectorization()\n","\n","tmp_vectorize.adapt(tmp_train_ds)\n","\n","vocab_size = tmp_vectorize.vocabulary_size()\n","print(f\"Vocab size after preprocessing: {vocab_size}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-22T14:27:13.162644Z","iopub.status.busy":"2023-10-22T14:27:13.161766Z","iopub.status.idle":"2023-10-22T14:27:14.595195Z","shell.execute_reply":"2023-10-22T14:27:14.594532Z","shell.execute_reply.started":"2023-10-22T14:27:13.162609Z"},"trusted":true},"outputs":[],"source":["batch_size = 32\n","VOCAB_TOKENS = 50000\n","\n","train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(len(X_train)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n","val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val)).shuffle(len(X_val)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n","\n","train_text = train_ds.map(lambda text, labels: text)\n","\n","vectorize = tf.keras.layers.TextVectorization(max_tokens=VOCAB_TOKENS)\n","\n","vectorize.adapt(train_text)\n","\n","vocab_size = vectorize.vocabulary_size()\n","print(f\"Total distinct words: {vocab_size}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-22T14:27:17.46074Z","iopub.status.busy":"2023-10-22T14:27:17.45992Z","iopub.status.idle":"2023-10-22T14:27:17.466501Z","shell.execute_reply":"2023-10-22T14:27:17.465541Z","shell.execute_reply.started":"2023-10-22T14:27:17.460709Z"},"trusted":true},"outputs":[],"source":["epochs = 20\n","\n","def fit_model(model):\n","    return model.fit(train_ds, epochs=epochs, validation_data=val_ds, callbacks=[tf.keras.callbacks.EarlyStopping(patience=3, monitor=\"val_accuracy\")])\n","\n","def plot_metrics(history):\n","    metrics = pd.DataFrame(history.history)\n","    metrics[['accuracy', 'val_accuracy']].plot()\n","    metrics[['loss', 'val_loss']].plot()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-22T14:27:48.477135Z","iopub.status.busy":"2023-10-22T14:27:48.476795Z","iopub.status.idle":"2023-10-22T14:37:20.961419Z","shell.execute_reply":"2023-10-22T14:37:20.96039Z","shell.execute_reply.started":"2023-10-22T14:27:48.477108Z"},"trusted":true},"outputs":[],"source":["%%time\n","\n","model = tf.keras.models.Sequential([\n","    vectorize,\n","    tf.keras.layers.Embedding(vocab_size, 8),\n","    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16)),\n","    tf.keras.layers.Dropout(0.2),\n","    tf.keras.layers.Dense(8, activation='relu'),\n","    tf.keras.layers.Dropout(0.2),\n","    tf.keras.layers.Dense(5, activation='softmax')])\n","\n","model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","history = fit_model(model)\n","print(f\"\\n***Final val_accuracy: {history.history['val_accuracy'][-1]:.2%}***\\n\")\n","\n","plot_metrics(history)"]},{"cell_type":"markdown","metadata":{},"source":["# Model analysis"]},{"cell_type":"markdown","metadata":{},"source":["## Confusion matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-22T14:42:29.506591Z","iopub.status.busy":"2023-10-22T14:42:29.506146Z","iopub.status.idle":"2023-10-22T14:42:37.65951Z","shell.execute_reply":"2023-10-22T14:42:37.658519Z","shell.execute_reply.started":"2023-10-22T14:42:29.506556Z"},"trusted":true},"outputs":[],"source":["train_text = train_ds.map(lambda text, labels: text)\n","\n","pred = model.predict(train_text)\n","true_labels = y_train\n","pred_labels = np.argmax(pred, axis=-1)\n","\n","cm = confusion_matrix(true_labels, pred_labels)\n","cm_disp = ConfusionMatrixDisplay(cm, display_labels=[1, 2, 3, 4, 5])\n","cm_disp.plot()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-22T14:42:37.6615Z","iopub.status.busy":"2023-10-22T14:42:37.661148Z","iopub.status.idle":"2023-10-22T14:42:39.740223Z","shell.execute_reply":"2023-10-22T14:42:39.739287Z","shell.execute_reply.started":"2023-10-22T14:42:37.661452Z"},"trusted":true},"outputs":[],"source":["val_text = val_ds.map(lambda text, labels: text)\n","\n","pred = model.predict(val_text)\n","true_labels = y_val\n","pred_labels = np.argmax(pred, axis=-1)\n","\n","cm = confusion_matrix(true_labels, pred_labels)\n","cm_disp = ConfusionMatrixDisplay(cm, display_labels=[1, 2, 3, 4, 5])\n","cm_disp.plot()"]},{"cell_type":"markdown","metadata":{},"source":["## Show bad predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-22T11:59:40.966302Z","iopub.status.busy":"2023-10-22T11:59:40.965916Z","iopub.status.idle":"2023-10-22T11:59:41.147951Z","shell.execute_reply":"2023-10-22T11:59:41.147025Z","shell.execute_reply.started":"2023-10-22T11:59:40.966273Z"},"trusted":true},"outputs":[],"source":["# Save some incorrect predictions as a csv\n","\n","num_samples = 20\n","\n","df_incorrect = pd.DataFrame(columns=[\"Review\", \"True label\", \"Predicted label\"])\n","\n","for review_batch, label_batch in val_ds:\n","    pred_batch = tf.argmax(model.predict(review_batch), axis=-1)\n","    incorrect_flags = (pred_batch != label_batch)\n","    incorrect_reviews = review_batch[incorrect_flags]\n","    df_incorrect = pd.concat(\n","        [\n","            df_incorrect,\n","            pd.DataFrame(\n","                {\n","                    \"Review\": review_batch[incorrect_flags],\n","                    \"True label\": label_batch[incorrect_flags] + 1,\n","                    \"Predicted label\": pred_batch[incorrect_flags] + 1\n","                }\n","            )\n","        ],\n","        ignore_index=True\n","    )\n","    \n","    if df_incorrect.shape[0] >= num_samples:\n","        break\n","        \n","df_incorrect = df_incorrect.iloc[:num_samples, :]\n","df_incorrect[\"Review\"] = df_incorrect[\"Review\"].astype(str)\n","\n","df_incorrect.to_csv(\"incorrect.csv\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-22T11:59:41.922493Z","iopub.status.busy":"2023-10-22T11:59:41.921749Z","iopub.status.idle":"2023-10-22T11:59:42.117435Z","shell.execute_reply":"2023-10-22T11:59:42.116358Z","shell.execute_reply.started":"2023-10-22T11:59:41.922454Z"},"trusted":true},"outputs":[],"source":["# Save some correct predictions as a csv\n","\n","num_samples = 20\n","\n","df_correct = pd.DataFrame(columns=[\"Review\", \"True label\", \"Predicted label\"])\n","\n","for review_batch, label_batch in val_ds:\n","    pred_batch = tf.argmax(model.predict(review_batch), axis=-1)\n","    correct_flags = (pred_batch == label_batch)\n","    correct_reviews = review_batch[correct_flags]\n","    df_correct = pd.concat(\n","        [\n","            df_correct,\n","            pd.DataFrame(\n","                {\n","                    \"Review\": review_batch[correct_flags],\n","                    \"True label\": label_batch[correct_flags] + 1,\n","                    \"Predicted label\": pred_batch[correct_flags] + 1\n","                }\n","            )\n","        ],\n","        ignore_index=True\n","    )\n","    \n","    if df_correct.shape[0] >= num_samples:\n","        break\n","\n","df_correct = df_correct.iloc[:num_samples, :]\n","df_correct[\"Review\"] = df_correct[\"Review\"].astype(str)\n","\n","df_correct.to_csv(\"correct.csv\", index=False)"]},{"cell_type":"markdown","metadata":{},"source":["# Next steps\n","\n","* Do stemming after stripping punctuation, so that words next to punctuation can be stemmed as well.\n","* Tune `TextVectorization` layer `max_tokens`."]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":897156,"sourceId":1526618,"sourceType":"datasetVersion"}],"dockerImageVersionId":30558,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":4}
